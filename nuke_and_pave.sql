-- =================================================================
-- MASTER SETUP SCRIPT: Stock Market Physics Engine
-- =================================================================

-- 1. CLEANUP (The "Nuke")
-- Wipes everything to ensure a clean start. 
-- Cascade handles dependencies automatically.
drop function if exists get_daily_market_vectors;
drop function if exists hybrid_graph_search;
drop table if exists knowledge_graph cascade;
drop table if exists news_vectors cascade;
drop table if exists stocks_ohlc cascade;

-- Enable Vector Extension
create extension if not exists vector;

-- =================================================================
-- 2. CREATE TABLES
-- =================================================================

-- A. The Particles (Stocks)
create table stocks_ohlc (
  id bigint generated by default as identity primary key,
  ticker text not null,
  date date not null,
  open numeric,
  high numeric,
  low numeric,
  close numeric,
  volume numeric,
  -- STRICT CONSTRAINT: No duplicate candles for the same ticker/day
  constraint stocks_ticker_date_key unique (ticker, date)
);

-- B. The Fields (News Vectors)
create table news_vectors (
  id bigint generated by default as identity primary key,
  ticker text not null, -- "MARKET" or specific ticker
  headline text not null,
  published_at timestamp with time zone,
  url text,
  embedding vector(1536),
  -- STRICT CONSTRAINT: No duplicate articles
  constraint news_vectors_url_key unique (url)
);

-- C. The Bonds (Graph Edges)
create table knowledge_graph (
  id bigint generated by default as identity primary key,
  source_node text not null,
  target_node text not null,
  edge_type text not null,
  weight float default 1.0,
  -- STRICT CONSTRAINT: No duplicate edges
  constraint kg_unique_edge unique (source_node, target_node, edge_type)
);

-- =================================================================
-- 3. CREATE INDEXES (Performance Tuning)
-- =================================================================

-- News Indexes
create index idx_news_published on news_vectors(published_at);
create index idx_news_ticker on news_vectors(ticker);

-- Graph Indexes (Crucial for Joins)
create index idx_kg_source on knowledge_graph(source_node);
create index idx_kg_target on knowledge_graph(target_node);
create index idx_kg_type on knowledge_graph(edge_type);

-- =================================================================
-- 4. CREATE FUNCTIONS (The Brain)
-- =================================================================

-- Function A: Hybrid Search (for RAG / Chat)
create or replace function hybrid_graph_search(
  query_embedding vector(1536), 
  match_threshold float, 
  match_count int
)
returns table (
  news_id bigint,
  headline text,
  similarity float,
  connected_ticker text,
  edge_type text
)
language plpgsql
as $$
begin
  return query
  with relevant_news as (
    select nv.id, nv.headline, 1 - (nv.embedding <=> query_embedding) as similarity
    from news_vectors nv
    where 1 - (nv.embedding <=> query_embedding) > match_threshold
    order by similarity desc
    limit match_count
  )
  select 
    rn.id, rn.headline, rn.similarity, kg.target_node, kg.edge_type
  from relevant_news rn
  left join knowledge_graph kg on cast(rn.id as text) = kg.source_node
  order by rn.similarity desc;
end;
$$;

-- Function B: Daily Vector Aggregation (for Physics Engine)
-- Includes Server-Side Paging to prevent timeouts
create or replace function get_daily_market_vectors(
  target_date date, 
  page_size int default 100, 
  page_num int default 0
)
returns table (ticker text, vector vector(1536))
language sql
as $$
  with daily_news as (
    -- Optimize: Filter news for the specific date FIRST
    select id, embedding
    from news_vectors
    where published_at >= target_date::timestamp
      and published_at < (target_date + 1)::timestamp
  )
  select 
    kg.target_node as ticker,
    avg(dn.embedding) as vector
  from daily_news dn
  -- Join only the small subset of daily news to the graph
  join knowledge_graph kg on kg.source_node = cast(dn.id as text)
  where kg.edge_type = 'MENTIONS'
  group by kg.target_node
  order by kg.target_node
  -- Pagination limits
  limit page_size offset (page_num * page_size);
$$;

-- =================================================================
-- 5. FINALIZATION
-- =================================================================

-- Refresh Schema Cache for Supabase API
NOTIFY pgrst, 'reload schema';

-- Update Query Planner Statistics
analyze stocks_ohlc;
analyze news_vectors;
analyze knowledge_graph;
